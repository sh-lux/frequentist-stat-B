{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist Inference Case Study - Part A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to part A of the Frequentist inference case study! The purpose of this case study is to help you apply the concepts associated with Frequentist inference in Python. Frequentist inference is the process of deriving conclusions about an underlying distribution via the observation of data. In particular, you'll practice writing Python code to apply the following statistical concepts: \n",
    "* the _z_-statistic\n",
    "* the _t_-statistic\n",
    "* the difference and relationship between the two\n",
    "* the Central Limit Theorem, including its assumptions and consequences\n",
    "* how to estimate the population mean and standard deviation from a sample\n",
    "* the concept of a sampling distribution of a test statistic, particularly for the mean\n",
    "* how to combine these concepts to calculate a confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to complete this notebook, you are expected to have a basic understanding of:\n",
    "* what a random variable is (p.400 of Professor Spiegelhalter's *The Art of Statistics, hereinafter AoS*)\n",
    "* what a population, and a population distribution, are (p. 397 of *AoS*)\n",
    "* a high-level sense of what the normal distribution is (p. 394 of *AoS*)\n",
    "* what the t-statistic is (p. 275 of *AoS*)\n",
    "\n",
    "Happily, these should all be concepts with which you are reasonably familiar after having read ten chapters of Professor Spiegelhalter's book, *The Art of Statistics*.\n",
    "\n",
    "We'll try to relate the concepts in this case study back to page numbers in *The Art of Statistics* so that you can focus on the Python aspects of this case study. The second part (part B) of this case study will involve another, more real-world application of these tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we will use data sampled from a known normal distribution. This allows us to compare our results with theoretical expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An introduction to sampling from the normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's explore the ways we can generate the normal distribution. While there's a fair amount of interest in [sklearn](https://scikit-learn.org/stable/) within the machine learning community, you're likely to have heard of [scipy](https://docs.scipy.org/doc/scipy-0.15.1/reference/index.html) if you're coming from the sciences. For this assignment, you'll use [scipy.stats](https://docs.scipy.org/doc/scipy-0.15.1/reference/tutorial/stats.html) to complete your work. \n",
    "\n",
    "This assignment will require some digging around and getting your hands dirty (your learning is maximized that way)! You should have the research skills and the tenacity to do these tasks independently, but if you struggle, reach out to your immediate community and your mentor for help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1:__ Call up the documentation for the `norm` function imported above. (Hint: that documentation is [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html)). What is the second listed method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on norm_gen in module scipy.stats._continuous_distns:\n",
      "\n",
      "<scipy.stats._continuous_distns.norm_gen object>\n",
      "    A normal continuous random variable.\n",
      "    \n",
      "    The location (``loc``) keyword specifies the mean.\n",
      "    The scale (``scale``) keyword specifies the standard deviation.\n",
      "    \n",
      "    As an instance of the `rv_continuous` class, `norm` object inherits from it\n",
      "    a collection of generic methods (see below for the full list),\n",
      "    and completes them with details specific for this particular distribution.\n",
      "    \n",
      "    Methods\n",
      "    -------\n",
      "    rvs(loc=0, scale=1, size=1, random_state=None)\n",
      "        Random variates.\n",
      "    pdf(x, loc=0, scale=1)\n",
      "        Probability density function.\n",
      "    logpdf(x, loc=0, scale=1)\n",
      "        Log of the probability density function.\n",
      "    cdf(x, loc=0, scale=1)\n",
      "        Cumulative distribution function.\n",
      "    logcdf(x, loc=0, scale=1)\n",
      "        Log of the cumulative distribution function.\n",
      "    sf(x, loc=0, scale=1)\n",
      "        Survival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).\n",
      "    logsf(x, loc=0, scale=1)\n",
      "        Log of the survival function.\n",
      "    ppf(q, loc=0, scale=1)\n",
      "        Percent point function (inverse of ``cdf`` --- percentiles).\n",
      "    isf(q, loc=0, scale=1)\n",
      "        Inverse survival function (inverse of ``sf``).\n",
      "    moment(n, loc=0, scale=1)\n",
      "        Non-central moment of order n\n",
      "    stats(loc=0, scale=1, moments='mv')\n",
      "        Mean('m'), variance('v'), skew('s'), and/or kurtosis('k').\n",
      "    entropy(loc=0, scale=1)\n",
      "        (Differential) entropy of the RV.\n",
      "    fit(data)\n",
      "        Parameter estimates for generic data.\n",
      "        See `scipy.stats.rv_continuous.fit <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html#scipy.stats.rv_continuous.fit>`__ for detailed documentation of the\n",
      "        keyword arguments.\n",
      "    expect(func, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      "        Expected value of a function (of one argument) with respect to the distribution.\n",
      "    median(loc=0, scale=1)\n",
      "        Median of the distribution.\n",
      "    mean(loc=0, scale=1)\n",
      "        Mean of the distribution.\n",
      "    var(loc=0, scale=1)\n",
      "        Variance of the distribution.\n",
      "    std(loc=0, scale=1)\n",
      "        Standard deviation of the distribution.\n",
      "    interval(alpha, loc=0, scale=1)\n",
      "        Endpoints of the range that contains fraction alpha [0, 1] of the\n",
      "        distribution\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The probability density function for `norm` is:\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "        f(x) = \\frac{\\exp(-x^2/2)}{\\sqrt{2\\pi}}\n",
      "    \n",
      "    for a real number :math:`x`.\n",
      "    \n",
      "    The probability density above is defined in the \"standardized\" form. To shift\n",
      "    and/or scale the distribution use the ``loc`` and ``scale`` parameters.\n",
      "    Specifically, ``norm.pdf(x, loc, scale)`` is identically\n",
      "    equivalent to ``norm.pdf(y) / scale`` with\n",
      "    ``y = (x - loc) / scale``. Note that shifting the location of a distribution\n",
      "    does not make it a \"noncentral\" distribution; noncentral generalizations of\n",
      "    some distributions are available in separate classes.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.stats import norm\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> fig, ax = plt.subplots(1, 1)\n",
      "    \n",
      "    Calculate the first four moments:\n",
      "    \n",
      "    \n",
      "    >>> mean, var, skew, kurt = norm.stats(moments='mvsk')\n",
      "    \n",
      "    Display the probability density function (``pdf``):\n",
      "    \n",
      "    >>> x = np.linspace(norm.ppf(0.01),\n",
      "    ...                 norm.ppf(0.99), 100)\n",
      "    >>> ax.plot(x, norm.pdf(x),\n",
      "    ...        'r-', lw=5, alpha=0.6, label='norm pdf')\n",
      "    \n",
      "    Alternatively, the distribution object can be called (as a function)\n",
      "    to fix the shape, location and scale parameters. This returns a \"frozen\"\n",
      "    RV object holding the given parameters fixed.\n",
      "    \n",
      "    Freeze the distribution and display the frozen ``pdf``:\n",
      "    \n",
      "    >>> rv = norm()\n",
      "    >>> ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
      "    \n",
      "    Check accuracy of ``cdf`` and ``ppf``:\n",
      "    \n",
      "    >>> vals = norm.ppf([0.001, 0.5, 0.999])\n",
      "    >>> np.allclose([0.001, 0.5, 0.999], norm.cdf(vals))\n",
      "    True\n",
      "    \n",
      "    Generate random numbers:\n",
      "    \n",
      "    >>> r = norm.rvs(size=1000)\n",
      "    \n",
      "    And compare the histogram:\n",
      "    \n",
      "    >>> ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
      "    >>> ax.legend(loc='best', frameon=False)\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The second listed method is the probability density function, denoted as pdf. It computes the value of the probability density function at value 'x'. The parameter 'loc' specifies the mean of the normal distribution we are creating, whereas the parameter 'scale' specifies the standard deviation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q2:__ Use the method that generates random variates to draw five samples from the standard normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84800948  1.30590636  0.92420797  0.6404118  -1.05473698]\n"
     ]
    }
   ],
   "source": [
    "seed(47)\n",
    "# draw five samples here\n",
    "samples = norm.rvs(size=5)\n",
    "\n",
    "# print the samples\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q3:__ What is the mean of this sample? Is it exactly equal to the value you expected? Hint: the sample was drawn from the standard normal distribution. If you want a reminder of the properties of this distribution, check out p. 85 of *AoS*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of our sample is 0.19355593334131074\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the mean here, hint: use np.mean()\n",
    "mean = np.mean(samples)\n",
    "print(\"The mean of our sample is\", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q4:__ What is the standard deviation of these numbers? Calculate this manually here as $\\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n}}$ (This is just the definition of **standard deviation** given by Professor Spiegelhalter on p.403 of *AoS*). Hint: np.sqrt() and np.sum() will be useful here and remember that numPy supports [broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.04156541  1.11235042  0.73065203  0.44685587 -1.24829292]\n",
      "The standard deviation is: 0.9606195639478641\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array containing the difference between sample values and mean. Print it.\n",
    "diff = samples - mean\n",
    "print(diff)\n",
    "\n",
    "# The numpy array diff*diff contains the square of the elements in diff. We sum over them and store the sum in the variable s:\n",
    "s = np.sum(diff*diff)\n",
    "\n",
    "# We compute the standard deviation as the square root of s/5\n",
    "print('The standard deviation is:', np.sqrt(s/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have calculated the actual standard deviation of a small data set (of size 5). But in this case, this small data set is actually a sample from our larger (infinite) population. In this case, the population is infinite because we could keep drawing our normal random variates until our computers die! \n",
    "\n",
    "In general, the sample mean we calculate will not be equal to the population mean (as we saw above). A consequence of this is that the sum of squares of the deviations from the _population_ mean will be bigger than the sum of squares of the deviations from the _sample_ mean. In other words, the sum of squares of the deviations from the _sample_ mean is too small to give an unbiased estimate of the _population_ variance. An example of this effect is given [here](https://en.wikipedia.org/wiki/Bessel%27s_correction#Source_of_bias). Scaling our estimate of the variance by the factor $n/(n-1)$ gives an unbiased estimator of the population variance. This factor is known as [Bessel's correction](https://en.wikipedia.org/wiki/Bessel%27s_correction). The consequence of this is that the $n$ in the denominator is replaced by $n-1$.\n",
    "\n",
    "You can see Bessel's correction reflected in Professor Spiegelhalter's definition of **variance** on p. 405 of *AoS*.\n",
    "\n",
    "__Q5:__ If all we had to go on was our five samples, what would be our best estimate of the population standard deviation? Use Bessel's correction ($n-1$ in the denominator), thus $\\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n-1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bessel-corrected standard deviation is: 1.0740053227518152\n"
     ]
    }
   ],
   "source": [
    "# We compute the Bessel-corrected std\n",
    "print('The Bessel-corrected standard deviation is:', np.sqrt(s/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q6:__ Now use numpy's std function to calculate the standard deviation of our random samples. Which of the above standard deviations did it return?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of our sample is 0.9606195639478641\n"
     ]
    }
   ],
   "source": [
    "std = np.std(samples)\n",
    "print(\"The standard deviation of our sample is\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q7:__ Consult the documentation for np.std() to see how to apply the correction for estimating the population parameter and verify this produces the expected result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function std in module numpy:\n",
      "\n",
      "std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)\n",
      "    Compute the standard deviation along the specified axis.\n",
      "    \n",
      "    Returns the standard deviation, a measure of the spread of a distribution,\n",
      "    of the array elements. The standard deviation is computed for the\n",
      "    flattened array by default, otherwise over the specified axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Calculate the standard deviation of these values.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which the standard deviation is computed. The\n",
      "        default is to compute the standard deviation of the flattened array.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If this is a tuple of ints, a standard deviation is performed over\n",
      "        multiple axes, instead of a single axis or all the axes as before.\n",
      "    dtype : dtype, optional\n",
      "        Type to use in computing the standard deviation. For arrays of\n",
      "        integer type the default is float64, for arrays of float types it is\n",
      "        the same as the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output but the type (of the calculated\n",
      "        values) will be cast if necessary.\n",
      "    ddof : int, optional\n",
      "        Means Delta Degrees of Freedom.  The divisor used in calculations\n",
      "        is ``N - ddof``, where ``N`` represents the number of elements.\n",
      "        By default `ddof` is zero.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `std` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    \n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the standard deviation.\n",
      "        See `~numpy.ufunc.reduce` for details.\n",
      "    \n",
      "        .. versionadded:: 1.20.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    standard_deviation : ndarray, see dtype parameter above.\n",
      "        If `out` is None, return a new array containing the standard deviation,\n",
      "        otherwise return a reference to the output array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    var, mean, nanmean, nanstd, nanvar\n",
      "    :ref:`ufuncs-output-type`\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The standard deviation is the square root of the average of the squared\n",
      "    deviations from the mean, i.e., ``std = sqrt(mean(x))``, where\n",
      "    ``x = abs(a - a.mean())**2``.\n",
      "    \n",
      "    The average squared deviation is typically calculated as ``x.sum() / N``,\n",
      "    where ``N = len(x)``. If, however, `ddof` is specified, the divisor\n",
      "    ``N - ddof`` is used instead. In standard statistical practice, ``ddof=1``\n",
      "    provides an unbiased estimator of the variance of the infinite population.\n",
      "    ``ddof=0`` provides a maximum likelihood estimate of the variance for\n",
      "    normally distributed variables. The standard deviation computed in this\n",
      "    function is the square root of the estimated variance, so even with\n",
      "    ``ddof=1``, it will not be an unbiased estimate of the standard deviation\n",
      "    per se.\n",
      "    \n",
      "    Note that, for complex numbers, `std` takes the absolute\n",
      "    value before squaring, so that the result is always real and nonnegative.\n",
      "    \n",
      "    For floating-point input, the *std* is computed using the same\n",
      "    precision the input has. Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for float32 (see example below).\n",
      "    Specifying a higher-accuracy accumulator using the `dtype` keyword can\n",
      "    alleviate this issue.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.std(a)\n",
      "    1.1180339887498949 # may vary\n",
      "    >>> np.std(a, axis=0)\n",
      "    array([1.,  1.])\n",
      "    >>> np.std(a, axis=1)\n",
      "    array([0.5,  0.5])\n",
      "    \n",
      "    In single precision, std() can be inaccurate:\n",
      "    \n",
      "    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n",
      "    >>> a[0, :] = 1.0\n",
      "    >>> a[1, :] = 0.1\n",
      "    >>> np.std(a)\n",
      "    0.45000005\n",
      "    \n",
      "    Computing the standard deviation in float64 is more accurate:\n",
      "    \n",
      "    >>> np.std(a, dtype=np.float64)\n",
      "    0.44999999925494177 # may vary\n",
      "    \n",
      "    Specifying a where argument:\n",
      "    \n",
      "    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])\n",
      "    >>> np.std(a)\n",
      "    2.614064523559687 # may vary\n",
      "    >>> np.std(a, where=[[True], [True], [False]])\n",
      "    2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bessel corrected sample standard deviation is 1.0740053227518152\n"
     ]
    }
   ],
   "source": [
    "std_b = np.std(samples, ddof=1)\n",
    "\n",
    "print(\"The Bessel corrected sample standard deviation is\", std_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you've been introduced to the scipy.stats package and used it to draw a small sample from the standard normal distribution. You've calculated the average (the mean) of this sample and seen that this is not exactly equal to the expected population parameter (which we know because we're generating the random variates from a specific, known distribution). You've been introduced to two ways of calculating the standard deviation; one uses $n$ in the denominator and the other uses $n-1$ (Bessel's correction). You've also seen which of these calculations np.std() performs by default and how to get it to generate the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You use $n$ as the denominator if you want to calculate the standard deviation of a sequence of numbers. You use $n-1$ if you are using this sequence of numbers to estimate the population parameter. This brings us to some terminology that can be a little confusing.\n",
    "\n",
    "The population parameter is traditionally written as $\\sigma$ and the sample statistic as $s$. Rather unhelpfully, $s$ is also called the sample standard deviation (using $n-1$) whereas the standard deviation of the sample uses $n$. That's right, we have the sample standard deviation and the standard deviation of the sample and they're not the same thing!\n",
    "\n",
    "The sample standard deviation\n",
    "\\begin{equation}\n",
    "s = \\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n-1}} \\approx \\sigma,\n",
    "\\end{equation}\n",
    "is our best (unbiased) estimate of the population parameter ($\\sigma$).\n",
    "\n",
    "If your dataset _is_ your entire population, you simply want to calculate the population parameter, $\\sigma$, via\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{n}}\n",
    "\\end{equation}\n",
    "as you have complete, full knowledge of your population. In other words, your sample _is_ your population. It's worth noting that we're dealing with what Professor Spiegehalter describes on p. 92 of *AoS* as a **metaphorical population**: we have all the data, and we act as if the data-point is taken from a population at random. We can think of this population as an imaginary space of possibilities. \n",
    "\n",
    "If, however, you have sampled _from_ your population, you only have partial knowledge of the state of your population. In this case, the standard deviation of your sample is not an unbiased estimate of the standard deviation of the population, in which case you seek to estimate that population parameter via the sample standard deviation, which uses the $n-1$ denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work so far! Now let's dive deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been dealing with the concept of taking a sample from a population to infer the population parameters. One statistic we calculated for a sample was the mean. As our samples will be expected to vary from one draw to another, so will our sample statistics. If we were to perform repeat draws of size $n$ and calculate the mean of each, we would expect to obtain a distribution of values. This is the sampling distribution of the mean. **The Central Limit Theorem (CLT)** tells us that such a distribution will approach a normal distribution as $n$ increases (the intuitions behind the CLT are covered in full on p. 236 of *AoS*). For the sampling distribution of the mean, the standard deviation of this distribution is given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{mean} = \\frac{\\sigma}{\\sqrt n}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma_{mean}$ is the standard deviation of the sampling distribution of the mean and $\\sigma$ is the standard deviation of the population (the population parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is important because typically we are dealing with samples from populations and all we know about the population is what we see in the sample. From this sample, we want to make inferences about the population. We may do this, for example, by looking at the histogram of the values and by calculating the mean and standard deviation (as estimates of the population parameters), and so we are intrinsically interested in how these quantities vary across samples. \n",
    "\n",
    "In other words, now that we've taken one sample of size $n$ and made some claims about the general population, what if we were to take another sample of size $n$? Would we get the same result? Would we make the same claims about the general population? This brings us to a fundamental question: _when we make some inference about a population based on our sample, how confident can we be that we've got it 'right'?_\n",
    "\n",
    "We need to think about **estimates and confidence intervals**: those concepts covered in Chapter 7, p. 189, of *AoS*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the standard normal distribution (with its variance equal to its standard deviation of one) would not be a great illustration of a key point. Instead, let's imagine we live in a town of 50,000 people and we know the height of everyone in this town. We will have 50,000 numbers that tell us everything about our population. We'll simulate these numbers now and put ourselves in one particular town, called 'town 47', where the population mean height is 172 cm and population standard deviation is 5 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(47)\n",
    "pop_heights = norm.rvs(172, 5, size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(pop_heights, bins=30)\n",
    "_ = plt.xlabel('height (cm)')\n",
    "_ = plt.ylabel('number of people')\n",
    "_ = plt.title('Distribution of heights in entire town population')\n",
    "_ = plt.axvline(172, color='r')\n",
    "_ = plt.axvline(172+5, color='r', linestyle='--')\n",
    "_ = plt.axvline(172-5, color='r', linestyle='--')\n",
    "_ = plt.axvline(172+10, color='r', linestyle='-.')\n",
    "_ = plt.axvline(172-10, color='r', linestyle='-.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, 50,000 people is rather a lot to chase after with a tape measure. If all you want to know is the average height of the townsfolk, then can you just go out and measure a sample to get a pretty good estimate of the average height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def townsfolk_sampler(n):\n",
    "    return np.random.choice(pop_heights, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you go out one day and randomly sample 10 people to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(47)\n",
    "daily_sample1 = townsfolk_sampler(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(daily_sample1, bins=10)\n",
    "_ = plt.xlabel('height (cm)')\n",
    "_ = plt.ylabel('number of people')\n",
    "_ = plt.title('Distribution of heights in sample size 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample distribution doesn't resemble what we take the population distribution to be. What do we get for the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.47911444163503"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(daily_sample1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we went out and repeated this experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sample2 = townsfolk_sampler(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.7317666636263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(daily_sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q8:__ Simulate performing this random trial every day for a year, calculating the mean of each daily sample of 10, and plot the resultant sampling distribution of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 1 Sample mean: 173.47911444163503\n",
      "Sample: 2 Sample mean: 173.7317666636263\n",
      "Sample: 3 Sample mean: 172.54893867276104\n",
      "Sample: 4 Sample mean: 171.43257319553967\n",
      "Sample: 5 Sample mean: 172.7151613148319\n",
      "Sample: 6 Sample mean: 172.82799509412092\n",
      "Sample: 7 Sample mean: 172.72104620090087\n",
      "Sample: 8 Sample mean: 171.35684251559897\n",
      "Sample: 9 Sample mean: 172.06082915612325\n",
      "Sample: 10 Sample mean: 175.02116165843373\n",
      "Sample: 11 Sample mean: 172.87297442836729\n",
      "Sample: 12 Sample mean: 173.10695709894807\n",
      "Sample: 13 Sample mean: 174.28251319331625\n",
      "Sample: 14 Sample mean: 172.16799412617846\n",
      "Sample: 15 Sample mean: 172.2677166306168\n",
      "Sample: 16 Sample mean: 174.1148759511088\n",
      "Sample: 17 Sample mean: 173.76989560652873\n",
      "Sample: 18 Sample mean: 173.53587661697912\n",
      "Sample: 19 Sample mean: 171.73109636549412\n",
      "Sample: 20 Sample mean: 173.6192933521118\n",
      "Sample: 21 Sample mean: 171.4122703231149\n",
      "Sample: 22 Sample mean: 169.8912622859572\n",
      "Sample: 23 Sample mean: 171.50855064552047\n",
      "Sample: 24 Sample mean: 170.79777102526515\n",
      "Sample: 25 Sample mean: 172.13293591535268\n",
      "Sample: 26 Sample mean: 174.04237966386012\n",
      "Sample: 27 Sample mean: 171.41699712312\n",
      "Sample: 28 Sample mean: 169.68751210980005\n",
      "Sample: 29 Sample mean: 170.70138979236123\n",
      "Sample: 30 Sample mean: 170.50288822335273\n",
      "Sample: 31 Sample mean: 171.1227335807866\n",
      "Sample: 32 Sample mean: 172.18184913764566\n",
      "Sample: 33 Sample mean: 172.68945746436543\n",
      "Sample: 34 Sample mean: 171.0001004904461\n",
      "Sample: 35 Sample mean: 170.89451146667253\n",
      "Sample: 36 Sample mean: 171.09020297014567\n",
      "Sample: 37 Sample mean: 171.25533609966612\n",
      "Sample: 38 Sample mean: 172.10797845540236\n",
      "Sample: 39 Sample mean: 171.08827013545948\n",
      "Sample: 40 Sample mean: 172.6513531230999\n",
      "Sample: 41 Sample mean: 175.070689805427\n",
      "Sample: 42 Sample mean: 169.97597644140453\n",
      "Sample: 43 Sample mean: 172.2797674841427\n",
      "Sample: 44 Sample mean: 169.68001261485807\n",
      "Sample: 45 Sample mean: 172.80409332096238\n",
      "Sample: 46 Sample mean: 172.55229420480956\n",
      "Sample: 47 Sample mean: 173.83054118621465\n",
      "Sample: 48 Sample mean: 173.37568836233626\n",
      "Sample: 49 Sample mean: 171.89359355779794\n",
      "Sample: 50 Sample mean: 171.6665742212276\n",
      "Sample: 51 Sample mean: 169.9004743876151\n",
      "Sample: 52 Sample mean: 172.72984382291025\n",
      "Sample: 53 Sample mean: 169.46043079819069\n",
      "Sample: 54 Sample mean: 171.9066883458138\n",
      "Sample: 55 Sample mean: 174.31024504533102\n",
      "Sample: 56 Sample mean: 172.9549236584936\n",
      "Sample: 57 Sample mean: 170.26013472404284\n",
      "Sample: 58 Sample mean: 171.62782407697222\n",
      "Sample: 59 Sample mean: 171.93287814147618\n",
      "Sample: 60 Sample mean: 172.67107823125573\n",
      "Sample: 61 Sample mean: 173.35560534761376\n",
      "Sample: 62 Sample mean: 171.5928923513852\n",
      "Sample: 63 Sample mean: 174.01996330433786\n",
      "Sample: 64 Sample mean: 168.70526103039566\n",
      "Sample: 65 Sample mean: 174.4291544932485\n",
      "Sample: 66 Sample mean: 172.99782989083792\n",
      "Sample: 67 Sample mean: 169.85679627411287\n",
      "Sample: 68 Sample mean: 170.51072224889845\n",
      "Sample: 69 Sample mean: 169.90321605710665\n",
      "Sample: 70 Sample mean: 170.15223960286718\n",
      "Sample: 71 Sample mean: 171.69847097209998\n",
      "Sample: 72 Sample mean: 172.1247564115574\n",
      "Sample: 73 Sample mean: 170.7393421379653\n",
      "Sample: 74 Sample mean: 169.418394777909\n",
      "Sample: 75 Sample mean: 172.90126387627427\n",
      "Sample: 76 Sample mean: 173.349965975603\n",
      "Sample: 77 Sample mean: 172.31408857482649\n",
      "Sample: 78 Sample mean: 170.95008031433505\n",
      "Sample: 79 Sample mean: 168.6026063397666\n",
      "Sample: 80 Sample mean: 169.23740477644245\n",
      "Sample: 81 Sample mean: 168.98395307845203\n",
      "Sample: 82 Sample mean: 170.24977041291908\n",
      "Sample: 83 Sample mean: 172.28866881866844\n",
      "Sample: 84 Sample mean: 169.4954901013438\n",
      "Sample: 85 Sample mean: 172.14048141305437\n",
      "Sample: 86 Sample mean: 170.63029872192917\n",
      "Sample: 87 Sample mean: 170.81450578452282\n",
      "Sample: 88 Sample mean: 172.7564010423859\n",
      "Sample: 89 Sample mean: 172.270704952318\n",
      "Sample: 90 Sample mean: 172.75102003444198\n",
      "Sample: 91 Sample mean: 170.29337424391514\n",
      "Sample: 92 Sample mean: 171.37511929823515\n",
      "Sample: 93 Sample mean: 171.19824057530133\n",
      "Sample: 94 Sample mean: 175.6782843800554\n",
      "Sample: 95 Sample mean: 169.98345772406594\n",
      "Sample: 96 Sample mean: 171.97617797193666\n",
      "Sample: 97 Sample mean: 170.56013527190584\n",
      "Sample: 98 Sample mean: 171.50909868435141\n",
      "Sample: 99 Sample mean: 172.75712339394886\n",
      "Sample: 100 Sample mean: 173.2095114832777\n",
      "Sample: 101 Sample mean: 172.10653392996448\n",
      "Sample: 102 Sample mean: 173.14812711662768\n",
      "Sample: 103 Sample mean: 170.10688635551668\n",
      "Sample: 104 Sample mean: 173.3757843013828\n",
      "Sample: 105 Sample mean: 172.1393269463663\n",
      "Sample: 106 Sample mean: 169.68126101129226\n",
      "Sample: 107 Sample mean: 173.51940617466894\n",
      "Sample: 108 Sample mean: 170.64933192553676\n",
      "Sample: 109 Sample mean: 172.9302606791998\n",
      "Sample: 110 Sample mean: 171.55990939669806\n",
      "Sample: 111 Sample mean: 171.92304718402258\n",
      "Sample: 112 Sample mean: 173.64455234145223\n",
      "Sample: 113 Sample mean: 171.97230993627605\n",
      "Sample: 114 Sample mean: 171.4139294230426\n",
      "Sample: 115 Sample mean: 173.09648158348617\n",
      "Sample: 116 Sample mean: 171.59077758086715\n",
      "Sample: 117 Sample mean: 172.02580024296842\n",
      "Sample: 118 Sample mean: 172.21608501143896\n",
      "Sample: 119 Sample mean: 172.0071934611132\n",
      "Sample: 120 Sample mean: 172.33599701625351\n",
      "Sample: 121 Sample mean: 171.028648188148\n",
      "Sample: 122 Sample mean: 173.3730965923039\n",
      "Sample: 123 Sample mean: 171.63339660555894\n",
      "Sample: 124 Sample mean: 172.24280703841163\n",
      "Sample: 125 Sample mean: 170.96259686809128\n",
      "Sample: 126 Sample mean: 175.03094575416975\n",
      "Sample: 127 Sample mean: 173.6428041806974\n",
      "Sample: 128 Sample mean: 172.95723098557428\n",
      "Sample: 129 Sample mean: 171.9821148360482\n",
      "Sample: 130 Sample mean: 172.86230119411863\n",
      "Sample: 131 Sample mean: 173.2818959291762\n",
      "Sample: 132 Sample mean: 170.74391386736906\n",
      "Sample: 133 Sample mean: 171.85618466569377\n",
      "Sample: 134 Sample mean: 174.516404929308\n",
      "Sample: 135 Sample mean: 171.9757816604739\n",
      "Sample: 136 Sample mean: 172.8532356879273\n",
      "Sample: 137 Sample mean: 170.8863347896039\n",
      "Sample: 138 Sample mean: 172.02699101055003\n",
      "Sample: 139 Sample mean: 171.00702877519421\n",
      "Sample: 140 Sample mean: 174.4668408638607\n",
      "Sample: 141 Sample mean: 167.8482928708372\n",
      "Sample: 142 Sample mean: 170.87326329719744\n",
      "Sample: 143 Sample mean: 172.24076331599596\n",
      "Sample: 144 Sample mean: 174.06036645523105\n",
      "Sample: 145 Sample mean: 173.65199868699432\n",
      "Sample: 146 Sample mean: 171.31020238919996\n",
      "Sample: 147 Sample mean: 172.8757717751434\n",
      "Sample: 148 Sample mean: 169.00973760863025\n",
      "Sample: 149 Sample mean: 169.36066339463133\n",
      "Sample: 150 Sample mean: 172.8394581127686\n",
      "Sample: 151 Sample mean: 173.2849490876725\n",
      "Sample: 152 Sample mean: 167.94708299375463\n",
      "Sample: 153 Sample mean: 171.4944813760528\n",
      "Sample: 154 Sample mean: 173.26676195725375\n",
      "Sample: 155 Sample mean: 174.36603867262343\n",
      "Sample: 156 Sample mean: 169.3835107781193\n",
      "Sample: 157 Sample mean: 170.81702577580646\n",
      "Sample: 158 Sample mean: 172.65881074097973\n",
      "Sample: 159 Sample mean: 170.5043935231086\n",
      "Sample: 160 Sample mean: 174.48530539837125\n",
      "Sample: 161 Sample mean: 169.28374480528095\n",
      "Sample: 162 Sample mean: 173.11587199242774\n",
      "Sample: 163 Sample mean: 169.48869927808207\n",
      "Sample: 164 Sample mean: 174.05802462897157\n",
      "Sample: 165 Sample mean: 170.41037396562533\n",
      "Sample: 166 Sample mean: 170.3850832762101\n",
      "Sample: 167 Sample mean: 171.14614333175618\n",
      "Sample: 168 Sample mean: 171.28870072653964\n",
      "Sample: 169 Sample mean: 172.76671420430083\n",
      "Sample: 170 Sample mean: 169.95471759650735\n",
      "Sample: 171 Sample mean: 172.86382182013728\n",
      "Sample: 172 Sample mean: 172.6225511373559\n",
      "Sample: 173 Sample mean: 172.33656268781826\n",
      "Sample: 174 Sample mean: 168.62332166556928\n",
      "Sample: 175 Sample mean: 172.7111357521249\n",
      "Sample: 176 Sample mean: 171.82186352481727\n",
      "Sample: 177 Sample mean: 173.28085693950445\n",
      "Sample: 178 Sample mean: 169.06595378147523\n",
      "Sample: 179 Sample mean: 174.0801392411933\n",
      "Sample: 180 Sample mean: 174.9773349255948\n",
      "Sample: 181 Sample mean: 171.28213572811805\n",
      "Sample: 182 Sample mean: 171.6730813592417\n",
      "Sample: 183 Sample mean: 169.45634682144438\n",
      "Sample: 184 Sample mean: 173.43393215657332\n",
      "Sample: 185 Sample mean: 170.86374559269453\n",
      "Sample: 186 Sample mean: 173.21556904620837\n",
      "Sample: 187 Sample mean: 169.1862678724352\n",
      "Sample: 188 Sample mean: 171.20026812399502\n",
      "Sample: 189 Sample mean: 171.47106714440469\n",
      "Sample: 190 Sample mean: 173.32428817479482\n",
      "Sample: 191 Sample mean: 171.2691694937409\n",
      "Sample: 192 Sample mean: 169.74157082970493\n",
      "Sample: 193 Sample mean: 172.91823143229223\n",
      "Sample: 194 Sample mean: 171.78081907440483\n",
      "Sample: 195 Sample mean: 170.11860847293156\n",
      "Sample: 196 Sample mean: 171.87026079537708\n",
      "Sample: 197 Sample mean: 170.74069830935466\n",
      "Sample: 198 Sample mean: 172.46488874903895\n",
      "Sample: 199 Sample mean: 172.98225023418647\n",
      "Sample: 200 Sample mean: 174.46081103471732\n",
      "Sample: 201 Sample mean: 173.49400936370455\n",
      "Sample: 202 Sample mean: 169.51557464300683\n",
      "Sample: 203 Sample mean: 171.73063129611373\n",
      "Sample: 204 Sample mean: 170.7169353336031\n",
      "Sample: 205 Sample mean: 174.6602048576773\n",
      "Sample: 206 Sample mean: 172.3849780185491\n",
      "Sample: 207 Sample mean: 172.79482744498335\n",
      "Sample: 208 Sample mean: 172.66798523120897\n",
      "Sample: 209 Sample mean: 173.03683236655385\n",
      "Sample: 210 Sample mean: 169.03388574785288\n",
      "Sample: 211 Sample mean: 170.27625725905142\n",
      "Sample: 212 Sample mean: 171.6548397802826\n",
      "Sample: 213 Sample mean: 173.9110065626827\n",
      "Sample: 214 Sample mean: 172.36666043469813\n",
      "Sample: 215 Sample mean: 173.0806786048489\n",
      "Sample: 216 Sample mean: 170.5454321114398\n",
      "Sample: 217 Sample mean: 171.63218644552478\n",
      "Sample: 218 Sample mean: 173.75734815005714\n",
      "Sample: 219 Sample mean: 173.4663602192376\n",
      "Sample: 220 Sample mean: 173.93185477413437\n",
      "Sample: 221 Sample mean: 172.21851080918435\n",
      "Sample: 222 Sample mean: 174.99259084185877\n",
      "Sample: 223 Sample mean: 172.79446184726748\n",
      "Sample: 224 Sample mean: 171.51052052455086\n",
      "Sample: 225 Sample mean: 173.24255009028505\n",
      "Sample: 226 Sample mean: 171.8830523292385\n",
      "Sample: 227 Sample mean: 172.78335534863947\n",
      "Sample: 228 Sample mean: 171.91694787219325\n",
      "Sample: 229 Sample mean: 170.12924519370299\n",
      "Sample: 230 Sample mean: 171.6125036310404\n",
      "Sample: 231 Sample mean: 172.90245069941636\n",
      "Sample: 232 Sample mean: 173.09703321285585\n",
      "Sample: 233 Sample mean: 172.13187273881533\n",
      "Sample: 234 Sample mean: 173.1671394346884\n",
      "Sample: 235 Sample mean: 170.08389854480225\n",
      "Sample: 236 Sample mean: 173.93739863468136\n",
      "Sample: 237 Sample mean: 171.3831801935383\n",
      "Sample: 238 Sample mean: 173.0648792145468\n",
      "Sample: 239 Sample mean: 171.67286845324548\n",
      "Sample: 240 Sample mean: 172.74454332610662\n",
      "Sample: 241 Sample mean: 170.29325491672353\n",
      "Sample: 242 Sample mean: 168.50440626366915\n",
      "Sample: 243 Sample mean: 172.52943025832766\n",
      "Sample: 244 Sample mean: 168.22985199166658\n",
      "Sample: 245 Sample mean: 173.63375684095035\n",
      "Sample: 246 Sample mean: 173.8223904901435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 247 Sample mean: 170.64928888578683\n",
      "Sample: 248 Sample mean: 171.7803289727296\n",
      "Sample: 249 Sample mean: 169.31058690937567\n",
      "Sample: 250 Sample mean: 170.90044256609488\n",
      "Sample: 251 Sample mean: 172.67827045507593\n",
      "Sample: 252 Sample mean: 172.0422309421312\n",
      "Sample: 253 Sample mean: 173.17659183674408\n",
      "Sample: 254 Sample mean: 169.49895501607463\n",
      "Sample: 255 Sample mean: 172.8853684043484\n",
      "Sample: 256 Sample mean: 173.3982671958468\n",
      "Sample: 257 Sample mean: 169.6718344723641\n",
      "Sample: 258 Sample mean: 169.3434812632541\n",
      "Sample: 259 Sample mean: 175.1631703883851\n",
      "Sample: 260 Sample mean: 170.59481340389107\n",
      "Sample: 261 Sample mean: 170.58426243494063\n",
      "Sample: 262 Sample mean: 172.72334025117496\n",
      "Sample: 263 Sample mean: 172.1307888143033\n",
      "Sample: 264 Sample mean: 169.01609630447473\n",
      "Sample: 265 Sample mean: 171.15681558897592\n",
      "Sample: 266 Sample mean: 174.684931280434\n",
      "Sample: 267 Sample mean: 169.29446475103575\n",
      "Sample: 268 Sample mean: 171.65686646102714\n",
      "Sample: 269 Sample mean: 173.8172097345154\n",
      "Sample: 270 Sample mean: 170.72391555094927\n",
      "Sample: 271 Sample mean: 170.5159267446483\n",
      "Sample: 272 Sample mean: 174.0926258645925\n",
      "Sample: 273 Sample mean: 168.74354262686796\n",
      "Sample: 274 Sample mean: 171.60449755276952\n",
      "Sample: 275 Sample mean: 173.35249290348906\n",
      "Sample: 276 Sample mean: 169.59524622005407\n",
      "Sample: 277 Sample mean: 172.31825115793964\n",
      "Sample: 278 Sample mean: 173.43051530494725\n",
      "Sample: 279 Sample mean: 175.97945459508188\n",
      "Sample: 280 Sample mean: 172.41542957870462\n",
      "Sample: 281 Sample mean: 172.48108913345823\n",
      "Sample: 282 Sample mean: 175.73235560113446\n",
      "Sample: 283 Sample mean: 173.30917671705808\n",
      "Sample: 284 Sample mean: 170.5016307174128\n",
      "Sample: 285 Sample mean: 171.47442800822694\n",
      "Sample: 286 Sample mean: 172.921116303701\n",
      "Sample: 287 Sample mean: 171.1639042540142\n",
      "Sample: 288 Sample mean: 173.15958685889186\n",
      "Sample: 289 Sample mean: 170.6199464194715\n",
      "Sample: 290 Sample mean: 170.84177739176616\n",
      "Sample: 291 Sample mean: 171.99038709269252\n",
      "Sample: 292 Sample mean: 174.23130175705404\n",
      "Sample: 293 Sample mean: 170.4855060493516\n",
      "Sample: 294 Sample mean: 172.02085224658146\n",
      "Sample: 295 Sample mean: 172.08650337240257\n",
      "Sample: 296 Sample mean: 173.12384811687497\n",
      "Sample: 297 Sample mean: 170.09817772721084\n",
      "Sample: 298 Sample mean: 171.4714587067785\n",
      "Sample: 299 Sample mean: 172.78753151796303\n",
      "Sample: 300 Sample mean: 172.85937740574727\n",
      "Sample: 301 Sample mean: 169.39067373385993\n",
      "Sample: 302 Sample mean: 172.88433436767303\n",
      "Sample: 303 Sample mean: 172.09661414856313\n",
      "Sample: 304 Sample mean: 172.27425697400423\n",
      "Sample: 305 Sample mean: 170.7114548591524\n",
      "Sample: 306 Sample mean: 172.19296597942235\n",
      "Sample: 307 Sample mean: 167.52865965907253\n",
      "Sample: 308 Sample mean: 172.32570464261443\n",
      "Sample: 309 Sample mean: 172.72742669079858\n",
      "Sample: 310 Sample mean: 172.5216957174198\n",
      "Sample: 311 Sample mean: 172.05940736419612\n",
      "Sample: 312 Sample mean: 168.8771648188222\n",
      "Sample: 313 Sample mean: 170.44810196307384\n",
      "Sample: 314 Sample mean: 173.01149455582384\n",
      "Sample: 315 Sample mean: 172.52292732563117\n",
      "Sample: 316 Sample mean: 169.7669347411906\n",
      "Sample: 317 Sample mean: 169.465402331526\n",
      "Sample: 318 Sample mean: 173.02223016664223\n",
      "Sample: 319 Sample mean: 170.27061511503928\n",
      "Sample: 320 Sample mean: 171.18421420659692\n",
      "Sample: 321 Sample mean: 173.06750477700962\n",
      "Sample: 322 Sample mean: 173.43258352486112\n",
      "Sample: 323 Sample mean: 171.82939845035773\n",
      "Sample: 324 Sample mean: 170.92672944980677\n",
      "Sample: 325 Sample mean: 169.81785832026858\n",
      "Sample: 326 Sample mean: 171.92871073981357\n",
      "Sample: 327 Sample mean: 170.34135388864743\n",
      "Sample: 328 Sample mean: 169.05442315458353\n",
      "Sample: 329 Sample mean: 172.84601765466334\n",
      "Sample: 330 Sample mean: 171.73522189318317\n",
      "Sample: 331 Sample mean: 169.2123811879794\n",
      "Sample: 332 Sample mean: 172.29730173923366\n",
      "Sample: 333 Sample mean: 169.99961438919348\n",
      "Sample: 334 Sample mean: 170.02830791269838\n",
      "Sample: 335 Sample mean: 171.75064789746975\n",
      "Sample: 336 Sample mean: 170.766935167691\n",
      "Sample: 337 Sample mean: 173.9810026650127\n",
      "Sample: 338 Sample mean: 169.92358516806348\n",
      "Sample: 339 Sample mean: 174.53205578998305\n",
      "Sample: 340 Sample mean: 173.21890262201072\n",
      "Sample: 341 Sample mean: 174.25370792104414\n",
      "Sample: 342 Sample mean: 172.91850748641357\n",
      "Sample: 343 Sample mean: 172.6887688830941\n",
      "Sample: 344 Sample mean: 172.064319088991\n",
      "Sample: 345 Sample mean: 169.88770099269323\n",
      "Sample: 346 Sample mean: 171.46079489790765\n",
      "Sample: 347 Sample mean: 171.48307828152147\n",
      "Sample: 348 Sample mean: 172.59879898682084\n",
      "Sample: 349 Sample mean: 172.37504542447692\n",
      "Sample: 350 Sample mean: 168.70639919115436\n",
      "Sample: 351 Sample mean: 172.76066642690037\n",
      "Sample: 352 Sample mean: 171.6634185490236\n",
      "Sample: 353 Sample mean: 173.98434386877807\n",
      "Sample: 354 Sample mean: 171.42827851034042\n",
      "Sample: 355 Sample mean: 171.77118445785496\n",
      "Sample: 356 Sample mean: 169.17922506646468\n",
      "Sample: 357 Sample mean: 173.782895546607\n",
      "Sample: 358 Sample mean: 170.82035700816542\n",
      "Sample: 359 Sample mean: 170.98291389030948\n",
      "Sample: 360 Sample mean: 172.02218170287054\n",
      "Sample: 361 Sample mean: 173.20080178649226\n",
      "Sample: 362 Sample mean: 172.85589043208137\n",
      "Sample: 363 Sample mean: 171.9024897421873\n",
      "Sample: 364 Sample mean: 170.45743937442882\n",
      "Sample: 365 Sample mean: 171.64487927395743\n"
     ]
    }
   ],
   "source": [
    "seed(47)\n",
    "# take your samples here\n",
    "\n",
    "# Initialize to 0 an array of 365 entries\n",
    "mean_sample = [0]*365\n",
    "\n",
    "# This for loop samples 365 times, computing the mean of each sample and storing them in the array mean_sample\n",
    "for i in range(0, 365):\n",
    "    sample = townsfolk_sampler(10)\n",
    "    mean_sample[i] = np.mean(sample)\n",
    "    print('Sample:', i+1, 'Sample mean:', mean_sample[i] )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mean_sample, bins = 10) \n",
    "plt.xlim(xmin=166, xmax = 178)\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is the distribution of the means of samples of size 10 taken from our population. The Central Limit Theorem tells us the expected mean of this distribution will be equal to the population mean, and standard deviation will be $\\sigma / \\sqrt n$, which, in this case, should be approximately 1.58."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q9:__ Verify the above results from the CLT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171.8660049358649"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the mean of the sample means. Should be close to 172.\n",
    "np.mean(mean_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5756704135286475"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standard deviation of the distribution of sample means. Should be close to 1.58. \n",
    "np.std(mean_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, in this instance, we knew our population parameters, that the average height really is 172 cm and the standard deviation is 5 cm, and we see some of our daily estimates of the population mean were as low as around 168 and some as high as 176."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q10:__ Repeat the above year's worth of samples but for a sample size of 50 (perhaps you had a bigger budget for conducting surveys that year)! Would you expect your distribution of sample means to be wider (more variable) or narrower (more consistent)? Compare your resultant summary statistics to those predicted by the CLT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 1 Mean sample: 172.7815108576788\n",
      "Sample: 2 Mean sample: 172.79757492503552\n",
      "Sample: 3 Mean sample: 172.9396310954854\n",
      "Sample: 4 Mean sample: 173.3542075784445\n",
      "Sample: 5 Mean sample: 171.1485580390421\n",
      "Sample: 6 Mean sample: 171.27023338249884\n",
      "Sample: 7 Mean sample: 171.57773042798325\n",
      "Sample: 8 Mean sample: 171.63862815675472\n",
      "Sample: 9 Mean sample: 171.96210793335894\n",
      "Sample: 10 Mean sample: 172.66373830647717\n",
      "Sample: 11 Mean sample: 171.6615364799722\n",
      "Sample: 12 Mean sample: 171.88936776644812\n",
      "Sample: 13 Mean sample: 172.4205753053962\n",
      "Sample: 14 Mean sample: 170.68416081476462\n",
      "Sample: 15 Mean sample: 171.37644563516122\n",
      "Sample: 16 Mean sample: 170.89082919619474\n",
      "Sample: 17 Mean sample: 170.63167276488755\n",
      "Sample: 18 Mean sample: 171.84458610711957\n",
      "Sample: 19 Mean sample: 171.7056952443146\n",
      "Sample: 20 Mean sample: 172.0024093610841\n",
      "Sample: 21 Mean sample: 172.17533172997156\n",
      "Sample: 22 Mean sample: 171.66803383747916\n",
      "Sample: 23 Mean sample: 172.41006409365593\n",
      "Sample: 24 Mean sample: 172.03517066252826\n",
      "Sample: 25 Mean sample: 171.84810905850273\n",
      "Sample: 26 Mean sample: 173.29507939012166\n",
      "Sample: 27 Mean sample: 172.47483621040422\n",
      "Sample: 28 Mean sample: 172.24808622542724\n",
      "Sample: 29 Mean sample: 171.7349369252512\n",
      "Sample: 30 Mean sample: 171.0791666560747\n",
      "Sample: 31 Mean sample: 172.0718628174714\n",
      "Sample: 32 Mean sample: 171.56980924327706\n",
      "Sample: 33 Mean sample: 171.27134293407755\n",
      "Sample: 34 Mean sample: 171.10827182706282\n",
      "Sample: 35 Mean sample: 171.83147861260113\n",
      "Sample: 36 Mean sample: 172.64522968251705\n",
      "Sample: 37 Mean sample: 171.34184833161441\n",
      "Sample: 38 Mean sample: 171.67949207236762\n",
      "Sample: 39 Mean sample: 171.1656798606149\n",
      "Sample: 40 Mean sample: 172.50378182453488\n",
      "Sample: 41 Mean sample: 172.02347109882115\n",
      "Sample: 42 Mean sample: 171.98370176182962\n",
      "Sample: 43 Mean sample: 172.25788852831275\n",
      "Sample: 44 Mean sample: 172.66663634007872\n",
      "Sample: 45 Mean sample: 172.95172682262927\n",
      "Sample: 46 Mean sample: 171.6650208749629\n",
      "Sample: 47 Mean sample: 172.27647892611563\n",
      "Sample: 48 Mean sample: 172.56057396442372\n",
      "Sample: 49 Mean sample: 170.63814005426747\n",
      "Sample: 50 Mean sample: 171.2926075648261\n",
      "Sample: 51 Mean sample: 172.05628333087486\n",
      "Sample: 52 Mean sample: 171.63431334474822\n",
      "Sample: 53 Mean sample: 171.12226067877384\n",
      "Sample: 54 Mean sample: 172.0354775555923\n",
      "Sample: 55 Mean sample: 171.66181713847348\n",
      "Sample: 56 Mean sample: 172.74777937134553\n",
      "Sample: 57 Mean sample: 172.69973603545813\n",
      "Sample: 58 Mean sample: 171.7412662455689\n",
      "Sample: 59 Mean sample: 172.16291010361644\n",
      "Sample: 60 Mean sample: 172.0680786949149\n",
      "Sample: 61 Mean sample: 171.47146681665058\n",
      "Sample: 62 Mean sample: 171.45929053786557\n",
      "Sample: 63 Mean sample: 171.38381920550947\n",
      "Sample: 64 Mean sample: 170.74187931219902\n",
      "Sample: 65 Mean sample: 171.81481490446072\n",
      "Sample: 66 Mean sample: 171.1811454661782\n",
      "Sample: 67 Mean sample: 170.65765062531491\n",
      "Sample: 68 Mean sample: 172.48449628255221\n",
      "Sample: 69 Mean sample: 172.3626008744472\n",
      "Sample: 70 Mean sample: 171.3248233563762\n",
      "Sample: 71 Mean sample: 172.32157836257954\n",
      "Sample: 72 Mean sample: 171.3575146428834\n",
      "Sample: 73 Mean sample: 172.01230012182947\n",
      "Sample: 74 Mean sample: 171.45586797475937\n",
      "Sample: 75 Mean sample: 172.60832644769337\n",
      "Sample: 76 Mean sample: 172.90923064763888\n",
      "Sample: 77 Mean sample: 171.8232960400748\n",
      "Sample: 78 Mean sample: 172.02353512146678\n",
      "Sample: 79 Mean sample: 172.69244683833068\n",
      "Sample: 80 Mean sample: 172.5943354823301\n",
      "Sample: 81 Mean sample: 171.99559210545397\n",
      "Sample: 82 Mean sample: 170.88697444561848\n",
      "Sample: 83 Mean sample: 171.1287369020899\n",
      "Sample: 84 Mean sample: 173.3049050979804\n",
      "Sample: 85 Mean sample: 172.69005486736165\n",
      "Sample: 86 Mean sample: 171.31418515136443\n",
      "Sample: 87 Mean sample: 171.93620537662483\n",
      "Sample: 88 Mean sample: 170.84661950770945\n",
      "Sample: 89 Mean sample: 171.9420815386141\n",
      "Sample: 90 Mean sample: 172.7083537460361\n",
      "Sample: 91 Mean sample: 172.1068195680666\n",
      "Sample: 92 Mean sample: 172.08204873872012\n",
      "Sample: 93 Mean sample: 172.0857165025829\n",
      "Sample: 94 Mean sample: 172.28737626070964\n",
      "Sample: 95 Mean sample: 172.04409392625038\n",
      "Sample: 96 Mean sample: 171.72714932124234\n",
      "Sample: 97 Mean sample: 171.6108994453248\n",
      "Sample: 98 Mean sample: 171.40343323871966\n",
      "Sample: 99 Mean sample: 172.30606391429757\n",
      "Sample: 100 Mean sample: 173.14332165770466\n",
      "Sample: 101 Mean sample: 172.27657327770484\n",
      "Sample: 102 Mean sample: 171.86275141603662\n",
      "Sample: 103 Mean sample: 171.50224664098383\n",
      "Sample: 104 Mean sample: 170.07952858877113\n",
      "Sample: 105 Mean sample: 172.5189009341571\n",
      "Sample: 106 Mean sample: 171.22251422041813\n",
      "Sample: 107 Mean sample: 172.67348326757946\n",
      "Sample: 108 Mean sample: 171.3293814179121\n",
      "Sample: 109 Mean sample: 171.00380509699332\n",
      "Sample: 110 Mean sample: 172.04855887469952\n",
      "Sample: 111 Mean sample: 172.35372679227385\n",
      "Sample: 112 Mean sample: 170.67921568704617\n",
      "Sample: 113 Mean sample: 172.99986959212052\n",
      "Sample: 114 Mean sample: 172.26329470364595\n",
      "Sample: 115 Mean sample: 172.0372815194926\n",
      "Sample: 116 Mean sample: 172.35291480579843\n",
      "Sample: 117 Mean sample: 172.11903049105516\n",
      "Sample: 118 Mean sample: 172.0066044678251\n",
      "Sample: 119 Mean sample: 172.46448231204985\n",
      "Sample: 120 Mean sample: 172.4842815283576\n",
      "Sample: 121 Mean sample: 173.0169980361144\n",
      "Sample: 122 Mean sample: 170.89881785435747\n",
      "Sample: 123 Mean sample: 171.42254596527545\n",
      "Sample: 124 Mean sample: 171.37289809789033\n",
      "Sample: 125 Mean sample: 171.2414752854563\n",
      "Sample: 126 Mean sample: 172.86603311439686\n",
      "Sample: 127 Mean sample: 172.39453776258665\n",
      "Sample: 128 Mean sample: 171.30716428108641\n",
      "Sample: 129 Mean sample: 171.4019540281487\n",
      "Sample: 130 Mean sample: 172.76196180965368\n",
      "Sample: 131 Mean sample: 172.32905324065024\n",
      "Sample: 132 Mean sample: 172.3554490722028\n",
      "Sample: 133 Mean sample: 172.5489706719045\n",
      "Sample: 134 Mean sample: 172.98899631619722\n",
      "Sample: 135 Mean sample: 171.2300829660369\n",
      "Sample: 136 Mean sample: 171.7600764723803\n",
      "Sample: 137 Mean sample: 171.15894560780814\n",
      "Sample: 138 Mean sample: 172.2999306331501\n",
      "Sample: 139 Mean sample: 171.83028602099984\n",
      "Sample: 140 Mean sample: 171.32862238423687\n",
      "Sample: 141 Mean sample: 170.77936767894244\n",
      "Sample: 142 Mean sample: 172.36292504264466\n",
      "Sample: 143 Mean sample: 172.0627351161584\n",
      "Sample: 144 Mean sample: 172.4572213189606\n",
      "Sample: 145 Mean sample: 171.47259301389403\n",
      "Sample: 146 Mean sample: 172.70448049640206\n",
      "Sample: 147 Mean sample: 170.9033793774536\n",
      "Sample: 148 Mean sample: 171.4977384620653\n",
      "Sample: 149 Mean sample: 171.92281752488395\n",
      "Sample: 150 Mean sample: 172.86154988875325\n",
      "Sample: 151 Mean sample: 172.8406753273718\n",
      "Sample: 152 Mean sample: 171.93324378922023\n",
      "Sample: 153 Mean sample: 171.74883388697694\n",
      "Sample: 154 Mean sample: 171.98380721046607\n",
      "Sample: 155 Mean sample: 171.46917463958798\n",
      "Sample: 156 Mean sample: 172.6146893473156\n",
      "Sample: 157 Mean sample: 172.91164033636466\n",
      "Sample: 158 Mean sample: 173.15753287968465\n",
      "Sample: 159 Mean sample: 172.27759829362836\n",
      "Sample: 160 Mean sample: 171.6774296769677\n",
      "Sample: 161 Mean sample: 171.54975020959088\n",
      "Sample: 162 Mean sample: 171.18582241213085\n",
      "Sample: 163 Mean sample: 171.66755046501711\n",
      "Sample: 164 Mean sample: 172.41658296742696\n",
      "Sample: 165 Mean sample: 173.04107187033074\n",
      "Sample: 166 Mean sample: 172.82076706195545\n",
      "Sample: 167 Mean sample: 171.46704286023976\n",
      "Sample: 168 Mean sample: 172.96233338098062\n",
      "Sample: 169 Mean sample: 172.12934776128904\n",
      "Sample: 170 Mean sample: 172.08330964582936\n",
      "Sample: 171 Mean sample: 171.8006916652453\n",
      "Sample: 172 Mean sample: 172.34308489334754\n",
      "Sample: 173 Mean sample: 171.88215305794077\n",
      "Sample: 174 Mean sample: 171.1559085024102\n",
      "Sample: 175 Mean sample: 171.85364449530417\n",
      "Sample: 176 Mean sample: 172.93460329977185\n",
      "Sample: 177 Mean sample: 173.18000857755993\n",
      "Sample: 178 Mean sample: 171.63724982728382\n",
      "Sample: 179 Mean sample: 173.4162760941612\n",
      "Sample: 180 Mean sample: 171.45107342933244\n",
      "Sample: 181 Mean sample: 170.76490777374693\n",
      "Sample: 182 Mean sample: 171.6380925465537\n",
      "Sample: 183 Mean sample: 171.74032428812748\n",
      "Sample: 184 Mean sample: 173.80301248510375\n",
      "Sample: 185 Mean sample: 171.74462296299367\n",
      "Sample: 186 Mean sample: 173.6235349342996\n",
      "Sample: 187 Mean sample: 171.2647502513369\n",
      "Sample: 188 Mean sample: 172.06979893037817\n",
      "Sample: 189 Mean sample: 172.17030823278597\n",
      "Sample: 190 Mean sample: 170.44348581706814\n",
      "Sample: 191 Mean sample: 172.73644707827924\n",
      "Sample: 192 Mean sample: 172.19090153359073\n",
      "Sample: 193 Mean sample: 170.6578604779148\n",
      "Sample: 194 Mean sample: 172.10099771905325\n",
      "Sample: 195 Mean sample: 171.71531553821683\n",
      "Sample: 196 Mean sample: 171.97867899672087\n",
      "Sample: 197 Mean sample: 171.99897228560974\n",
      "Sample: 198 Mean sample: 172.4364591414134\n",
      "Sample: 199 Mean sample: 171.1243322935377\n",
      "Sample: 200 Mean sample: 172.03204756684772\n",
      "Sample: 201 Mean sample: 171.30211257997559\n",
      "Sample: 202 Mean sample: 172.00669486226315\n",
      "Sample: 203 Mean sample: 172.38311872523292\n",
      "Sample: 204 Mean sample: 171.33568707613824\n",
      "Sample: 205 Mean sample: 171.33985719376716\n",
      "Sample: 206 Mean sample: 171.95870433759694\n",
      "Sample: 207 Mean sample: 171.1496261610421\n",
      "Sample: 208 Mean sample: 172.5782952059696\n",
      "Sample: 209 Mean sample: 172.42033433556662\n",
      "Sample: 210 Mean sample: 171.54928742914416\n",
      "Sample: 211 Mean sample: 172.5723730532069\n",
      "Sample: 212 Mean sample: 171.56614037303956\n",
      "Sample: 213 Mean sample: 171.37921101331048\n",
      "Sample: 214 Mean sample: 171.52449936229027\n",
      "Sample: 215 Mean sample: 171.33306899210882\n",
      "Sample: 216 Mean sample: 171.82625547275902\n",
      "Sample: 217 Mean sample: 171.44376529985166\n",
      "Sample: 218 Mean sample: 171.9873267301407\n",
      "Sample: 219 Mean sample: 172.0094762498349\n",
      "Sample: 220 Mean sample: 172.81511936308092\n",
      "Sample: 221 Mean sample: 171.91731067977227\n",
      "Sample: 222 Mean sample: 172.0977196544409\n",
      "Sample: 223 Mean sample: 172.32574513267085\n",
      "Sample: 224 Mean sample: 172.60347671265737\n",
      "Sample: 225 Mean sample: 172.44053362590222\n",
      "Sample: 226 Mean sample: 170.7468452174613\n",
      "Sample: 227 Mean sample: 170.98868067184708\n",
      "Sample: 228 Mean sample: 171.84561306662016\n",
      "Sample: 229 Mean sample: 171.8761956044929\n",
      "Sample: 230 Mean sample: 173.16669451210873\n",
      "Sample: 231 Mean sample: 171.758230409592\n",
      "Sample: 232 Mean sample: 172.31744287207303\n",
      "Sample: 233 Mean sample: 172.26066373967592\n",
      "Sample: 234 Mean sample: 172.90387119314428\n",
      "Sample: 235 Mean sample: 172.1542094707465\n",
      "Sample: 236 Mean sample: 172.41611963294156\n",
      "Sample: 237 Mean sample: 170.69078115925237\n",
      "Sample: 238 Mean sample: 172.74649501887535\n",
      "Sample: 239 Mean sample: 171.07615434950935\n",
      "Sample: 240 Mean sample: 172.02698832176975\n",
      "Sample: 241 Mean sample: 172.00554677262645\n",
      "Sample: 242 Mean sample: 172.74745263250585\n",
      "Sample: 243 Mean sample: 171.65945615758167\n",
      "Sample: 244 Mean sample: 172.42931787037676\n",
      "Sample: 245 Mean sample: 171.31139266156774\n",
      "Sample: 246 Mean sample: 172.86340638614564\n",
      "Sample: 247 Mean sample: 172.63046912414976\n",
      "Sample: 248 Mean sample: 171.90607197945067\n",
      "Sample: 249 Mean sample: 170.72003646709956\n",
      "Sample: 250 Mean sample: 172.10949275660838\n",
      "Sample: 251 Mean sample: 171.45152053467376\n",
      "Sample: 252 Mean sample: 171.86770717358283\n",
      "Sample: 253 Mean sample: 171.39371405813117\n",
      "Sample: 254 Mean sample: 172.14407557961246\n",
      "Sample: 255 Mean sample: 171.86145845615715\n",
      "Sample: 256 Mean sample: 171.0643157579227\n",
      "Sample: 257 Mean sample: 171.11107165580725\n",
      "Sample: 258 Mean sample: 171.97515142159185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 259 Mean sample: 172.2507452119935\n",
      "Sample: 260 Mean sample: 172.1856139091256\n",
      "Sample: 261 Mean sample: 172.4867254532553\n",
      "Sample: 262 Mean sample: 172.62914954558713\n",
      "Sample: 263 Mean sample: 172.8416069041034\n",
      "Sample: 264 Mean sample: 172.95766914878197\n",
      "Sample: 265 Mean sample: 173.10461610473183\n",
      "Sample: 266 Mean sample: 171.41466281567926\n",
      "Sample: 267 Mean sample: 171.89091850205338\n",
      "Sample: 268 Mean sample: 171.91765493682541\n",
      "Sample: 269 Mean sample: 171.3856728570194\n",
      "Sample: 270 Mean sample: 172.5580115051518\n",
      "Sample: 271 Mean sample: 170.83751768580808\n",
      "Sample: 272 Mean sample: 172.60219501605832\n",
      "Sample: 273 Mean sample: 171.7505797307657\n",
      "Sample: 274 Mean sample: 171.9617303911309\n",
      "Sample: 275 Mean sample: 171.84660491414547\n",
      "Sample: 276 Mean sample: 172.35776791909186\n",
      "Sample: 277 Mean sample: 171.2458779978962\n",
      "Sample: 278 Mean sample: 171.93438007088704\n",
      "Sample: 279 Mean sample: 171.8606276617006\n",
      "Sample: 280 Mean sample: 171.84556709017835\n",
      "Sample: 281 Mean sample: 171.44970933561854\n",
      "Sample: 282 Mean sample: 172.74576860936187\n",
      "Sample: 283 Mean sample: 170.38777847996414\n",
      "Sample: 284 Mean sample: 172.3466863540159\n",
      "Sample: 285 Mean sample: 172.8038464437931\n",
      "Sample: 286 Mean sample: 171.91877900815456\n",
      "Sample: 287 Mean sample: 172.66506616836838\n",
      "Sample: 288 Mean sample: 170.78590101157235\n",
      "Sample: 289 Mean sample: 172.11850648936783\n",
      "Sample: 290 Mean sample: 170.75665956609814\n",
      "Sample: 291 Mean sample: 171.7151020651713\n",
      "Sample: 292 Mean sample: 172.10742863250215\n",
      "Sample: 293 Mean sample: 172.51206031029852\n",
      "Sample: 294 Mean sample: 171.65287206192647\n",
      "Sample: 295 Mean sample: 172.55011484163367\n",
      "Sample: 296 Mean sample: 171.80014021314176\n",
      "Sample: 297 Mean sample: 171.68322902960838\n",
      "Sample: 298 Mean sample: 171.72240274574912\n",
      "Sample: 299 Mean sample: 171.58157929787114\n",
      "Sample: 300 Mean sample: 172.89233455637458\n",
      "Sample: 301 Mean sample: 171.35548749762108\n",
      "Sample: 302 Mean sample: 171.21277983252344\n",
      "Sample: 303 Mean sample: 172.50712890942086\n",
      "Sample: 304 Mean sample: 170.60810840182512\n",
      "Sample: 305 Mean sample: 172.58764074576774\n",
      "Sample: 306 Mean sample: 172.59321378019294\n",
      "Sample: 307 Mean sample: 172.75315782350623\n",
      "Sample: 308 Mean sample: 171.78472781834543\n",
      "Sample: 309 Mean sample: 170.56401239103522\n",
      "Sample: 310 Mean sample: 172.65025382629744\n",
      "Sample: 311 Mean sample: 172.50016154070934\n",
      "Sample: 312 Mean sample: 171.01133751509252\n",
      "Sample: 313 Mean sample: 171.89707218069572\n",
      "Sample: 314 Mean sample: 171.39777017939866\n",
      "Sample: 315 Mean sample: 171.5888706941444\n",
      "Sample: 316 Mean sample: 172.17453748533066\n",
      "Sample: 317 Mean sample: 172.5422328160275\n",
      "Sample: 318 Mean sample: 171.25478419429447\n",
      "Sample: 319 Mean sample: 171.48147133549224\n",
      "Sample: 320 Mean sample: 171.46642822745997\n",
      "Sample: 321 Mean sample: 171.58713991008008\n",
      "Sample: 322 Mean sample: 172.04420677191985\n",
      "Sample: 323 Mean sample: 172.82918744818838\n",
      "Sample: 324 Mean sample: 172.51828644828274\n",
      "Sample: 325 Mean sample: 172.5579170585349\n",
      "Sample: 326 Mean sample: 170.41746242201705\n",
      "Sample: 327 Mean sample: 172.21333956770403\n",
      "Sample: 328 Mean sample: 170.64348987977087\n",
      "Sample: 329 Mean sample: 172.4764043893837\n",
      "Sample: 330 Mean sample: 171.8229891306343\n",
      "Sample: 331 Mean sample: 170.67173816614144\n",
      "Sample: 332 Mean sample: 172.6966076913146\n",
      "Sample: 333 Mean sample: 171.6376245764548\n",
      "Sample: 334 Mean sample: 172.02274650961598\n",
      "Sample: 335 Mean sample: 172.59149521166134\n",
      "Sample: 336 Mean sample: 173.04572889665104\n",
      "Sample: 337 Mean sample: 171.42114339710554\n",
      "Sample: 338 Mean sample: 171.9158785872262\n",
      "Sample: 339 Mean sample: 172.52349847658462\n",
      "Sample: 340 Mean sample: 171.99752954585546\n",
      "Sample: 341 Mean sample: 172.6785554217261\n",
      "Sample: 342 Mean sample: 171.36004753537688\n",
      "Sample: 343 Mean sample: 171.60437385324246\n",
      "Sample: 344 Mean sample: 172.2211546793179\n",
      "Sample: 345 Mean sample: 171.55142175857543\n",
      "Sample: 346 Mean sample: 171.1090944569839\n",
      "Sample: 347 Mean sample: 171.0826709592788\n",
      "Sample: 348 Mean sample: 172.4930814954672\n",
      "Sample: 349 Mean sample: 171.0924260704737\n",
      "Sample: 350 Mean sample: 172.17588303663732\n",
      "Sample: 351 Mean sample: 172.3121000669372\n",
      "Sample: 352 Mean sample: 171.559746981286\n",
      "Sample: 353 Mean sample: 172.96717428468912\n",
      "Sample: 354 Mean sample: 170.9695688866329\n",
      "Sample: 355 Mean sample: 172.40049192809616\n",
      "Sample: 356 Mean sample: 172.8644173394355\n",
      "Sample: 357 Mean sample: 171.11341965338775\n",
      "Sample: 358 Mean sample: 170.43821023646333\n",
      "Sample: 359 Mean sample: 171.3745857265041\n",
      "Sample: 360 Mean sample: 172.38010537944785\n",
      "Sample: 361 Mean sample: 173.39919328106328\n",
      "Sample: 362 Mean sample: 172.57927553982918\n",
      "Sample: 363 Mean sample: 171.7523151509625\n",
      "Sample: 364 Mean sample: 171.92714893397323\n",
      "Sample: 365 Mean sample: 172.78806643087367\n"
     ]
    }
   ],
   "source": [
    "seed(47)\n",
    "# calculate daily means from the larger sample size here\n",
    "\n",
    "mean_sample = [0]*365\n",
    "\n",
    "for i in range(0, 365):\n",
    "    sample = townsfolk_sampler(50)\n",
    "    mean_sample[i] = np.mean(sample)\n",
    "    print('Sample:', i+1, 'Mean sample:', mean_sample[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of our distribution of sample means is: 171.94366080916114\n",
      "The standard deviation is: 0.6736107539771146\n"
     ]
    }
   ],
   "source": [
    "plt.hist(mean_sample, bins = 10) \n",
    "plt.xlim(xmin=166, xmax = 178)\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print('The mean of our distribution of sample means is:', np.mean(mean_sample))\n",
    "\n",
    "print('The standard deviation is:', np.std(mean_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've seen so far, then, is that we can estimate population parameters from a sample from the population, and that samples have their own distributions. Furthermore, the larger the sample size, the narrower are those sampling distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normally testing time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above is well and good. We've been sampling from a population we know is normally distributed, we've come to understand when to use $n$ and when to use $n-1$ in the denominator to calculate the spread of a distribution, and we've  seen the Central Limit Theorem in action for a sampling distribution. All seems very well behaved in Frequentist land. But, well, why should we really care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we rarely (if ever) actually know our population parameters but we still have to estimate them somehow. If we want to make inferences to conclusions like \"this observation is unusual\" or \"my population mean has changed\" then we need to have some idea of what the underlying distribution is so we can calculate relevant probabilities. In frequentist inference, we use the formulae above to deduce these population parameters. Take a moment in the next part of this assignment to refresh your understanding of how these probabilities work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall some basic properties of the standard normal distribution, such as that about 68% of observations are within plus or minus 1 standard deviation of the mean. Check out the precise definition of a normal distribution on p. 394 of *AoS*. \n",
    "\n",
    "__Q11:__ Using this fact, calculate the probability of observing the value 1 or less in a single observation from the standard normal distribution. Hint: you may find it helpful to sketch the standard normal distribution (the familiar bell shape) and mark the number of standard deviations from the mean on the x-axis and shade the regions of the curve that contain certain percentages of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__\n",
    "\n",
    "We want to compute the area under the standard normal distribution when we go in the x axis from x--> - Infinity to x = 1. We know that the total area under the normal distribution is 1 (the total probability). Since the normal distribution is symmetric with respect to the mean -which in our case is 0-, the area under the region going from -Infinity to 0 is 0.5. The standard deviation of the standard normal distribution is 1, and so the area under the region determined by the interval [-1,1] in the x axis is about 0.68. Adding up the area under the normal distribution in the ranges (-Infinity, 0) and [0,1] yields a probability of about 0.84. This is the probability of observing the value 1 or less in a single observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating this probability involved calculating the area under the curve from the value of 1 and below. To put it in mathematical terms, we need to *integrate* the probability density function. We could just add together the known areas of chunks (from -Inf to 0 and then 0 to $+\\sigma$ in the example above). One way to do this is to look up tables (literally). Fortunately, scipy has this functionality built in with the cdf() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q12:__ Use the cdf() function to answer the question above again and verify you get the same answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8413447460685429"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q13:__ Using our knowledge of the population parameters for our townsfolks' heights, what is the probability of selecting one person at random and their height being 177 cm or less? Calculate this using both of the approaches given above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8413447460685429"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(loc=172, scale=5).cdf(177)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q14:__ Turning this question around — suppose we randomly pick one person and measure their height and find they are 2.00 m tall. How surprised should we be at this result, given what we know about the population distribution? In other words, how likely would it be to obtain a value at least as extreme as this? Express this as a probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0717590259723409e-08"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-norm(loc=172, scale=5).cdf(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've just done is calculate the ***p-value*** of the observation of someone 2.00m tall (review *p*-values if you need to on p. 399 of *AoS*). We could calculate this probability by virtue of knowing the population parameters. We were then able to use the known properties of the relevant normal distribution to calculate the probability of observing a value at least as extreme as our test value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're about to come to a pinch, though. We've said a couple of times that we rarely, if ever, know the true population parameters; we have to estimate them from our sample and we cannot even begin to estimate the standard deviation from a single observation. \n",
    "\n",
    "This is very true and usually we have sample sizes larger than one. This means we can calculate the mean of the sample as our best estimate of the population mean and the standard deviation as our best estimate of the population standard deviation. \n",
    "\n",
    "In other words, we are now coming to deal with the sampling distributions we mentioned above as we are generally concerned with the properties of the sample means we obtain. \n",
    "\n",
    "Above, we highlighted one result from the CLT, whereby the sampling distribution (of the mean) becomes narrower and narrower with the square root of the sample size. We remind ourselves that another result from the CLT is that _even if the underlying population distribution is not normal, the sampling distribution will tend to become normal with sufficiently large sample size_. (**Check out p. 199 of AoS if you need to revise this**). This is the key driver for us 'requiring' a certain sample size, for example you may frequently see a minimum sample size of 30 stated in many places. In reality this is simply a rule of thumb; if the underlying distribution is approximately normal then your sampling distribution will already be pretty normal, but if the underlying distribution is heavily skewed then you'd want to increase your sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q15:__ Let's now start from the position of knowing nothing about the heights of people in our town.\n",
    "* Use the random seed of 47, to randomly sample the heights of 50 townsfolk\n",
    "* Estimate the population mean using np.mean\n",
    "* Estimate the population standard deviation using np.std (remember which denominator to use!)\n",
    "* Calculate the (95%) [margin of error](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/margin-of-error/#WhatMofE) (use the exact critial z value to 2 decimal places - [look this up](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/find-critical-values/) or use norm.ppf()) Recall that the ***margin of error*** is mentioned on p. 189 of the *AoS* and discussed in depth in that chapter). \n",
    "* Calculate the 95% Confidence Interval of the mean (***confidence intervals*** are defined on p. 385 of *AoS*) \n",
    "* Does this interval include the true population mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(47)\n",
    "# take your sample now\n",
    "sample = townsfolk_sampler(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample mean is: 172.7815108576788\n"
     ]
    }
   ],
   "source": [
    "print('The sample mean is:', np.mean(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample standard deviation is: 4.195424364433547\n"
     ]
    }
   ],
   "source": [
    "print('The sample standard deviation is:', np.std(sample, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.96\n",
      "Margin of error: 1.162912303074119\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard error of the sample mean\n",
    "std_error = np.std(sample, ddof=1) / np.sqrt(len(sample))\n",
    "\n",
    "# Round the critical z value to two decimal places. The 0.975 comes from setting alpha = 0.05 for 95% confidence\n",
    "# and compute the percent point function for 1-alpha/2\n",
    "z_critical_rounded = round(norm.ppf(0.975), 2)\n",
    "\n",
    "print(z_critical_rounded)\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = z_critical_rounded * std_error\n",
    "\n",
    "# print the margin of error\n",
    "print(\"Margin of error:\", margin_of_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (171.6185985546047, 173.9444231607529)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the lower and upper bounds of the confidence interval\n",
    "lower_bound = np.mean(sample) - margin_of_error\n",
    "upper_bound = np.mean(sample) + margin_of_error\n",
    "\n",
    "# Print the confidence interval\n",
    "print(\"95% Confidence Interval:\", (lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the 95% confidence interval includes the true population mean. The 95% confidence interval is saying that, if we did not know the true population mean, we would be 95% confident of finding it within the interval (171.6185985, 173.9444231). So it is hardly surprising that 172 is included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q16:__ Above, we calculated the confidence interval using the critical z value. What is the problem with this? What requirement, or requirements, are we (strictly) failing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__\n",
    "\n",
    "The critical z value is used for calculating confidence intervals whenever we know the population standard deviation. In this exercise we are interested in computing confidence intervals from the sample parameters, as if we did not know the population distribution (although we know that the population distribution is a normal). In particular, we are estimating the standard error from the sample standard deviation, which should not be mixed up with using the z score: t-statistics is the suitable approach instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q17:__ Calculate the 95% confidence interval for the mean using the _t_ distribution. Is this wider or narrower than that based on the normal distribution above? If you're unsure, you may find this [resource](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/confidence-interval/) useful. For calculating the critical value, remember how you could calculate this for the normal distribution using norm.ppf()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval (t-distribution): (171.589184447403, 173.9738372679546)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the critical t value for a 95% confidence interval\n",
    "df = len(sample) - 1  # degrees of freedom\n",
    "t_critical = t.ppf(0.975, df)\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = t_critical * std_error\n",
    "\n",
    "# Calculate the lower and upper bounds of the confidence interval\n",
    "lower_bound = np.mean(sample) - margin_of_error\n",
    "upper_bound = np.mean(sample) + margin_of_error\n",
    "\n",
    "# Print the confidence interval\n",
    "print(\"95% Confidence Interval (t-distribution):\", (lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the confidence interval based on the normal distribution, the confidence interval based on\n",
    "the t-distribution is wider. This is because the t-distribution has fatter tails than the normal distribution, \n",
    "which means that it assigns more probability to extreme values and therefore has more uncertainty in the estimation \n",
    "of the population mean. As a result, the critical t value is larger (in absolute value) than the critical z value, \n",
    "which leads to a wider margin of error and a wider confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly wider than the previous confidence interval. This reflects the greater uncertainty given that we are estimating population parameters from a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed this project notebook, you now have hands-on experience:\n",
    "* sampling and calculating probabilities from a normal distribution\n",
    "* identifying the correct way to estimate the standard deviation of a population (the population parameter) from a sample\n",
    "* with sampling distribution and now know how the Central Limit Theorem applies\n",
    "* with how to calculate critical values and confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
